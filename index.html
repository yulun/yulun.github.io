<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Yulun Zhang's Homepage</title>
<style type="text/css">
<!--
.STYLE8 {
	font-family: Georgia, "Times New Roman", Times, serif;
	font-size: 32px;
	font-style: italic;
	color: #000033;
}
body,td,th {
	font-family: Times New Roman, Times, serif;
	font-size: 18px;
}
.STYLE17 {font-family: Georgia, "Times New Roman", Times, serif}
.STYLE18 {font-size: 18px}
.STYLE34 {font-size: 16px}
.STYLE35 {color: #CCCCCC}
.STYLE75 {color: #0000FF}
.STYLE80 {color: #000000}
.STYLE85 {font-family: "Times New Roman", Times, serif; color: #000066; font-weight: bold; font-size: 22px; }
a:link {
	text-decoration: none;
	color: #0099FF;
}
a:visited {
	text-decoration: none;
}
a:hover {
	text-decoration: none;
	color: #009933;
}
a:active {
	text-decoration: none;
}
.STYLE90 {color: #FF0000; font-weight: bold; }
.STYLE98 {
	color: #333333;
	font-weight: bold;
	font-size: 14px;
}
.STYLE100 {color: #CC0033; font-size: 20px; font-style: italic; font-family: "Times New Roman", Times, serif;}
.STYLE109 {
	font-size: 18pt;
	color: #CC0033;
}
.STYLE122 {
	color: #F91F06;
	font-size: 16px;
}
.STYLE132 {color: #0066FF}
.STYLE136 {font-size: 22pt}
.STYLE137 {font-weight: bold; color: #333333;}
.STYLE141 {color: #0000CC; font-weight: bold; }
.STYLE157 {
	color: green;
	font-weight: bold;
}
.STYLE162 {font-family: Arial, Helvetica, sans-serif; font-size: 14px; font-style: italic; }
.STYLE178 {color: green; font-weight: bold; font-size: 16pt; }
.STYLE180 {color: #FF0000}
.STYLE186 {font-weight: bold; color: #4f4f4f; }
.STYLE188 {
	color: #4f4f4f;
	font-family: Arial, Helvetica, sans-serif;
	font-size: 14px;
}
.STYLE189 {
	font-family: Arial, Helvetica, sans-serif;
	font-size: 14px;
}
.STYLE193 {font-size: 14px}
.STYLE197 {font-family: Arial, Helvetica, sans-serif}
.STYLE198 {font-size: 17px; font-family: Arial, Helvetica, sans-serif; }
.STYLE200 {
	font-size: 14px;
	font-family: Arial, Helvetica, sans-serif;
	color: #4f4f4f;
}
.STYLE202 {
	color: #33CC00;
	font-weight: bold;
}
.STYLE203 {font-size: 14px; font-family: Arial, Helvetica, sans-serif; color: #4f4f4f; font-weight: bold; }
.STYLE212 {	color: #0033FF;
	font-family: "Courier New", Courier, monospace;
	font-weight: bold;
	font-size: 16;
}
.STYLE216 {color: #0033FF; font-weight: bold; font-size: 16; }
.STYLE217 {color: #0033FF; font-family: "Courier New", Courier, monospace; }
.STYLE220 {color: #333333; font-family: Arial, Helvetica, sans-serif; font-size: 14px;}
.STYLE223 {font-size: 14px; color: #666666; font-family: Arial, Helvetica, sans-serif;}
.STYLE225 {color: #FF0000; font-size: 16pt; }
.STYLE227 {font-size: 17px}
.STYLE228 {color: #008000}
.STYLE233 {font-family: "华文楷体"}
.STYLE235 {font-size: 14px; font-weight: bold; }
.STYLE237 {
	font-size: 16pt;
	color: #000000;
}
.STYLE238 {font-size: 24px}
.STYLE239 {font-size: 18pt}
.STYLE246 {font-style: italic}
.STYLE248 {font-weight: bold; color: #333333; font-size: 16pt; }
.STYLE249 {color: green}
.STYLE250 {font-weight: bold; color: #4f4f4f; font-size: 16pt; }
.STYLE251 {color: green; font-weight: bold; font-size: 18pt; }
.STYLE256 {font-size: 17px; font-family: Arial, Helvetica, sans-serif; font-weight: bold; }
.STYLE257 {
	color: #6666FF;
	font-weight: bold;
}
.STYLE258 {font-size: 18pt; color: #6666FF; }
.STYLE260 {font-size: 22pt; color: #6666FF; }
.STYLE262 {color: #6666FF}
.STYLE263 {color: #0099FF}
.STYLE265 {
	font-family: "宋体";
	font-size: 12px;
}
.STYLE266 {font-family: "华文楷体"; font-size: 14px; }
.STYLE267 {color: #333333; font-weight: bold; font-size: 14px; font-family: Arial, Helvetica, sans-serif; }
-->
</style>
</head>

<body>
<blockquote>
  <table border="0" width="99%">
    <tbody>
      <tr>
        <td width="15%" height="215"><div align="center" class="STYLE90" src="">
            <div align="left"><a href="http://yulunzhang.com"><img src="./img/yulun512.png" alt="Yulun Zhang" width="223" height="234" hspace="0" vspace="0" border="2" class="STYLE35" /></a></div>
        </div></td>
        <td width="85%"><p><br />
          <span class="STYLE85"> <a href="http://yulunzhang.com/">Yulun Zhang 张宇伦</a></span><br />
          <br />
              <!--<span class="STYLE200">Room 427, Richards Hall<a href="mailto:jian.zhang@pku.edu.cn" class="STYLE189"><br />-->
            </a></span><span class="STYLE200">Department of Electrical and Computer Engineering<br />
            </a></span><span class="STYLE200">Northeastern University</span><span class="STYLE200"><br />
            </a></span></p>
          <p><span class="STYLE200">Room 427, Richards Hall<br />
            </a></span><span class="STYLE200">360 Huntington Avenue, Boston, MA 02115, USA<br />
            </a></span></p>
          <p><span class="STYLE200">Email: yulun100 AT gmail DOT com<br />
            <!--</a>Email: OR zhangyl14 AT tsinghua.org.cn<br />
            </a>Phone: +1(617)849-0935<br />
            </a>Skype: yulun100<br />
            </a>Homepage: <a href="http://yulunzhang.com/">http://yulunzhang.com</a><br />-->
            </span><br />
            <span class="STYLE200">[<a href="papers/CV_YulunZhang.pdf">CV</a>] [<a href="https://scholar.google.com/citations?user=ORmLjWoAAAAJ&amp;hl=en">Google Scholar</a>] [<a href="http://dblp.org/pers/hd/z/Zhang:Yulun">DBLP</a>] [<a href="https://www.]edin.com/in/yulun-zhang-1116b5b9/">LinkedIn</a>]</span></span><span class="STYLE200"> [<a href="https://github.com/yulunzhang">Github</a>]</span></span><br />
            <span class="STYLE256"><br />
            </span><span class="STYLE198"><br />
        </span></p></td>
      </tr>
    </tbody>
  </table>
  <br />
  <table width="814" border="0" align="left" cellspacing="4" bordercolor="#999999">
    <tr bordercolor="#333333">
      <th width="111" scope="col"><a href="#biography" class="STYLE212">Biography</a></th>
      <th width="93" height="30" scope="col"><div align="center"><span class="STYLE212"><a href="#news">News</a></span></div></th>
      <th width="123" scope="col"><div align="center"><span class="STYLE217" style="font-size: 16"><b style="mso-bidi-font-weight: normal"><a href="#Education">Education</a></b></span></div></th>
      <th width="142" scope="col"><div align="center"><span class="STYLE217" style="font-size: 16"><b style="mso-bidi-font-weight: normal"><a href="#Publications">Publications</a></b></span></div></th>
      <th width="123" scope="col"><div align="center"><span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="#Activities">Activities</a></span></div></th>
      <th width="88" scope="col"><div align="center"><a href="#Awards" class="STYLE212">Awards</a></div></th>
      <th width="88" scope="col"><div align="center"><span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="http://124.207.250.90/staff/zhangjian/link/"><b 
style="mso-bidi-font-weight: normal"></b></a></span><span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="http://csjianzhang.github.io/link/">Links<b 
style="mso-bidi-font-weight: normal"> </b></a></span></div>
        <span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="http://124.207.250.90/staff/zhangjian/link/"><b 
style="mso-bidi-font-weight: normal"><o:p></o:p>
      </b></a></span>
        <div align="center"><span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="http://124.207.250.90/staff/zhangjian/link/"><b 
style="mso-bidi-font-weight: normal"></b></a></span><span class="STYLE216" style="font-family: &quot;Courier New&quot;, Courier, monospace"><a href="http://124.207.250.90/staff/zhangjian/link/"><b 
style="mso-bidi-font-weight: normal"></b></a></span></div></th>
    </tr>
  </table>
  <p><br />
    <br />
  </p>
  <hr />
  <p align="justify"><span class="subtitle1"><span style="font-size: 22pt"><b style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Monotype Corsiva'; COLOR: green; mso-bidi-font-family: Arial"><a name="Bio" id="Bio"></a><span class="STYLE258">Biography</span></span></b></span><span class="STYLE257" style="font-size: 18pt"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
    <o:p></o:p>
  </span></span></span><br />
    <br />
    <span class="STYLE200"> I am a PhD student at Department of Electrical &amp; Computer Engineering, Northeastern University, USA  and work with <a href="http://www1.ece.neu.edu/~yunfu/">Prof. Yun (Raymond) Fu</a> in the <a href="https://web.northeastern.edu/smilelab/"><strong>SMILE</strong></a> Lab. Before that I received my master degree in the Department of Automation, Tsinghua University, China, in Jul. 2017 and B.E degree from School of Electronic Engineering, Xidian University, China, in Jul. 2013. From Mar. 2014, I was working with my master advisor Prof. <a href="http://medialab.sz.tsinghua.edu.cn/people/YongbingZhang.html" target="_blank" rel="nofollow">Yongbing Zhang</a> on image restoration in both <a href="http://media.au.tsinghua.edu.cn/people.jsp" target="_blank" rel="nofollow">Broadband Network &amp; Digital Media Lab</a> and <a href="http://medialab.sz.tsinghua.edu.cn/" target="_blank" rel="nofollow">Shenzhen Key Lab of Broadband Network and Multimedia</a>, Tsinghua University. I was a visiting student (Jan. 2016 ~ Jul. 2016) in School of Electrical and Information Engineering, <a href="https://sydney.edu.au/">The University of Sydney</a>, Australia, under the supervision of <a href="http://sydney.edu.au/engineering/electrical/people/dong.xu/biography.html">Prof. Dong Xu</a>.</span></p>
  <p align="justify"><span class="STYLE200">My research interest broadly includes sparse/collaborative representation, deep learning and their applications to computer vision tasks. Specifically, these applications lie in image processing (image restoration, generation, and style transfer) and visual recognition (face recognition/veriﬁcation).</span><span class="STYLE17"><span class="STYLE188"> I was the recipient of the <a href="img/VCIP2015best student paper-web.jpg">Best Student Paper Award</a> at IEEE International Conference on Visual Communication and Image Processing (VCIP) in  2015. </span></span></p>
  <p align="justify"><span class="subtitle1"><span style="font-size: 22pt"><b style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Monotype Corsiva'; COLOR: green; mso-bidi-font-family: Arial"><a name="news" id="news"></a><span class="STYLE258">News</span></span></b></span><span class="STYLE257" style="font-size: 18pt"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
    <o:p></o:p>
  </span></span></span></p>
  <ul class="STYLE223">
    <li class="STYLE200">04/2019: We release all the train/test codes and pre-trained models for ICLR19RNAN at <a href="https://github.com/yulunzhang/RNAN">RNAN</a>.</li>
    <li class="STYLE200">12/2018: We have 1 paper accepted to <strong>ICLR 2019</strong>.</li>
    <li class="STYLE200">07/2018: PyTorch version for our CVPR18RDN has been implemented by Nguyễn Trần Toàn (trantoan060689@gmail.com) and merged into <a href="https://github.com/thstkdgus35/EDSR-PyTorch">EDSR-PyTorch</a>.</li>
    <li class="STYLE200">07/2018: We have 1 paper accepted to <strong>ECCV 2018</strong>.</li>
    <li class="STYLE200">07/2018: We have 1 paper accepted to <strong>ACM MM 2018</strong>.</li>
    <li class="STYLE200">06/2018: I accept the invitation to serve as Program Committee member of <strong>AAAI 2019</strong>.</li>
    <li class="STYLE200">02/2018: We have 1 paper accepted to <strong>CVPR 2018</strong> as spotlight. All the codes are available at <a href="https://github.com/yulunzhang/RDN">Github</a>.</li>
    <li class="STYLE200">02/2018: I will intern to <strong><a href="https://research.adobe.com/">Adobe Research</a></strong> (San Jose, CA) this summer.</li>
    <li class="STYLE200">07/2017: I recieve '<strong><a href="http://suisf.sz.edu.cn/20170713gg.htm">Shenzhen Universiade International Scholarship</a></strong>'.</li>
    <li class="STYLE200">07/2017: I recieve '<strong>Excellent Master Thesis Award, Tsinghua University</strong>' award.</li>
    <li class="STYLE200">07/2017: I recieve '<strong>Excellent Graduate in Department of Automation, Tsinghua University</strong>' award.</li>
    <li class="STYLE200">06/2017: I recieve '<strong>Excellent Graduate of Beijing</strong>' award.</li>
    <li class="STYLE200">05/2017: We have 1 IEEE  <strong>TSMC</strong> paper accepted.</li>
    <li class="STYLE200">05/2017: <a href="img/CVPR17NTIRE-SecondAward.jpg">Our team (HelloSR: Xintao Wang, Yapeng Tian, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao) ranks <strong>2nd</strong> place</a> in <a href="http://www.vision.ee.ethz.ch/ntire17/">NTIRE Image Super-Resolution Challenge</a>.</li>
  </ul>
  <hr />
  <p align="justify" class="subtitle1"><span style="font-size: 22pt"><b style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Monotype Corsiva'; COLOR: green; mso-bidi-font-family: Arial"><a name="Education" id="Education"></a><span class="STYLE258">Education</span></span></b><span class="STYLE257" style="font-size: 18pt"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
  <o:p></o:p>
  </span></span><span style="color: #6666FF"><b 
style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
  <o:p></o:p>
  </span></b></span><b 
style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Bauhaus 93'; COLOR: green; mso-bidi-font-family: Arial">
  <o:p></o:p>
  </span></b></span>  </p>
  <ul>
    <li class="STYLE189"><span class="subtitle1 STYLE122 STYLE189 STYLE193" align="justify"><strong>Ph.D. Student </strong></span> in Computer Engineering<br />
      <span class="STYLE246"><a href="http://www.hit.edu.cn/">Department of Electrical and Computer Engineering, Northeastern University, Boston, USA</a></span><span class="STYLE162">, Sep. 2017 ~ Present </span></li>
    <li class="STYLE189"><span class="STYLE141">M. E. Degree</span><span class="STYLE80"> in </span>Control Engineering<br />
        <em><a href="http://www.tsinghua.edu.cn/">Department of Automation, Tsinghua University, Beijing, China</a>, Sep. 2014 ~ Jul. 2017</em></li>
    <li class="STYLE189"><span class="STYLE186">B. S. Degree </span><span class="STYLE80"> in </span>Intelligence Science and Technology<span class="STYLE189"><br />
          <em><a href="http://www.xidian.edu.cn/">School of Electronic Engineering, Xidian University, Xi'an, China<span class="STYLE80">,</span> </a>Sep. 2009 ~ Jul. 2013　　</em></span><span class="STYLE162">　</span><br />
    </li>
  </ul>
  <p align="justify" class="STYLE85"><span class="subtitle1 STYLE136"><b style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Monotype Corsiva'; COLOR: green; mso-bidi-font-family: Arial"><a name="ResearchExp" id="ResearchExp"></a><span class="STYLE258">Research Experiences</span></span><span class="STYLE239" 
style="FONT-FAMILY: 'Bauhaus 93'; COLOR: #6666FF; mso-bidi-font-family: Arial">
    <o:p></o:p>
  </span></b></span></p>
  <ul>
    <li class="STYLE189"><span class="STYLE80"><span class="STYLE137">Research Intern</span></span>  <br />
      <em>Adobe Research<span class="STYLE80">,</span><a href="http://www.tsinghua.edu.cn">	<span class="STYLE80"> US, May. 2018 ~ Aug. 2018 </span></a></em></li>
    <li class="STYLE189"><span class="STYLE80"><span class="STYLE137">Research Assistant</span></span>  <br />
      <em>Department of Automation<span class="STYLE80">,</span><a href="http://www.tsinghua.edu.cn">	Tsinghua University<span class="STYLE80">, China, Mar. 2014 ~ Jul. 2017 </span></a></em></li>
    <li class="STYLE189"><span class="STYLE80"><span class="STYLE137">Research Assistant</span></span><span class="STYLE189"><a href="http://www.siat.cas.cn/">  <br />
          <em>Shenzhen Institutes of Advanced Technology (SIAT)<span class="STYLE80">,</span></em></a> <em><a href="http://english.cas.cn/">Chinese Academy of Science</a>, China, Nov. 2016 ~ Jun. 2017</em></span><br />
    </li>
    <li class="STYLE189"><span class="STYLE80"><span class="STYLE137">Project Officer</span></span><span class="STYLE189">  <br />
          <em>School of Computer Engineering<span class="STYLE80">,</span></em> <em><a href="http://www.ntu.edu.sg">Nanyang Technological University</a>, Singapore, Nov. 2015 ~ Jan. 2016</em></span><br />
    </li>
  </ul>
  <hr />
  <span class="subtitle1 STYLE136"><span style="font-style: italic"><b style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Monotype Corsiva'; COLOR: green; mso-bidi-font-family: Arial"><a name="Publications" id="Publications"></a><span class="STYLE258">Publications</span></span></b></span></span> &nbsp;<span class="STYLE200"><a href="https://scholar.google.com/citations?user=ORmLjWoAAAAJ&amp;hl=en">Google Scholar</a> </span>
  <p class="STYLE248"><span class="STYLE249" style="font-family: 'Monotype Corsiva'; font-weight: bold;">-</span><span style="font-family: 'Monotype Corsiva'; color: #333333;"><strong>Journal Articles </strong></span></p>
  <table width="101%" height="130" border="0" cellpadding="1" cellspacing="1" bordercolor="#FF0000">
    <tbody>
      <tr>
        <td height="128" class="STYLE188"><ol>

          <li>
            <div align="justify">
              <p><strong>Residual Dense Network for Image Restoration</strong> [<a href="https://arxiv.org/pdf/1812.10477.pdf">PDF</a>] [<a href="https://github.com/yulunzhang/RDN/tree/master/RDN_IR/RDN_TestCode">Code</a>] <br />
                <strong>Yulun Zhang</strong>, Yapeng Tian, Yu Kong, Bineng Zhong, Yun Fu <br />
                <em>arXiv preprint arXiv:1812.10477, 2018.</em></p>
            </div>
          </li>        
          <li>
            <div align="justify">
              <p><strong>Hierarchical Tracking by Reinforcement Learning based Searching and Coarse-to-fine Verifying</strong> [<a href="https://ieeexplore.ieee.org/document/8561254">PDF</a>] [Code] <br />
                Bineng Zhong, Bing Bai, Jun Li, <strong>Yulun Zhang</strong>, Yun Fu <br />
                <em><a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing </a><strong>(TIP, IF: 5.071)</strong>,  vol. 28, no. 5, pp. 2331-2341, 2019.</em></p>
            </div>
          </li>
          <li>
            <div align="justify">
              <p><strong>Deep Alignment Network Based Multi-person Tracking with Occlusion and Motion Reasoning</strong> [<a href="https://ieeexplore.ieee.org/document/8488599">PDF</a>] [Code] <br />
                Qinqin Zhou, Bineng Zhong, <strong>Yulun Zhang</strong>, Jun Li, Yun Fu <br />
                <em><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia </a><strong>(TMM, IF: 3.977)</strong>,  vol. xx, no. xx, pp. xxx, 2018.</em></p>
            </div>
          </li>
          <li>
            <div align="justify">
              <p><strong>Collaborative Representation Cascade for Single-Image Super-Resolution</strong> [<a href="/papers/TSMC-2017-CRC-early access.pdf">PDF</a>] [<a href="https://github.com/yulunzhang/CRC-SISR">Code-Github</a>] [<a href="http://pan.baidu.com/s/1dEBPvf7">Code-Baidu</a>] <br />
                Yongbing Zhang, <strong>Yulun Zhang*</strong>, Jian Zhang, Dong Xu, Yun Fu, Yisen Wang, Xiangyang Ji, Qionghai Dai <br />
                <em><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Systems, Man, and Cybernetics: Systems
                </a><strong>(TSMC, IF: 5.131)</strong>,  vol. PP, no. 99, pp. 1-16, 2017.</em></p>
              </div>
          </li>
          <li>
            <div align="justify">
              <p><strong>CCR: Clustering and Collaborative Representation for Fast Single Image Super-Resolution</strong> [<a href="papers/TMM-2016-CCR-Zhang.pdf">PDF</a>] [<a href="https://drive.google.com/drive/folders/0B7arHHh7oU7geUlyWE5iMl9mR1E?usp=sharing">Code</a>] [<a href="https://github.com/yulunzhang/CCR-SISR">Code-Github</a>] [<a href="http://pan.baidu.com/s/1hsEw1ZQ">Code-Baidu-with mode</a>]<br />
                Yongbing Zhang, <strong>Yulun Zhang*</strong>, Jian Zhang, Qionghai Dai <br />
                <em><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia </a><strong>(TMM, IF: 3.977)</strong>,  vol. 18, no. 3, pp. 405-417, Mar. 2016.</em></p>
            </div>
          </li>
          </ol></td>
      </tr>
    </tbody>
  </table>
  <p class="STYLE250"><span style="font-family: 'Monotype Corsiva';">-Conference Papers </span></p>
  <table width="101%" border="0" cellpadding="1" cellspacing="1" bordercolor="#FF0000">
    <tbody>
      <tr>
        <td class="STYLE188"><ol>

        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Multimodal Style Transfer via Graph Cuts</strong> [<a href="https://arxiv.org/pdf/1904.04443.pdf">PDF</a>] [<a href="papers/MST_supp_arXiv.pdf">Supplementary</a>] [TensorFlow]<br />
                <strong>Yulun Zhang</strong>, Chen Fang, Yilin Wang, Zhaowen Wang, Zhe Lin, Yun Fu, Jimei Yang<br />
                <em>arXiv, 2019.</em><br />
              </p>
            </div>
          </div>
        </li>

	<li>
            <div align="justify">
              <p><strong>TDAN: Temporally Deformable Alignment Network for Video Super-Resolution</strong> [<a href="https://arxiv.org/pdf/1812.02898.pdf">PDF</a>] [Code] <br />
                Yapeng Tian, <strong>Yulun Zhang</strong>, Yun Fu, Chenliang Xu <br />
                <em>arXiv preprint arXiv:1812.02898, 2018.</em></p>
            </div>
        </li>
        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Residual Non-local Attention Networks for Image Restoration </strong> [<a href="https://openreview.net/pdf?id=HkeGhoA5FX">PDF</a>] [<a href="https://github.com/yulunzhang/RNAN">PyTorch</a>]<br />
                <strong>Yulun Zhang</strong>, Kunpeng Li, Kai Li, Bineng Zhong, Yun Fu<br />
                <em>International Conference on Learning Representations (<strong>ICLR 2019</strong>), New Orleans, USA, May 2019.</em><br />
              </p>
            </div>
          </div>
        </li>
		
        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Image Super-Resolution Using Very Deep Residual Channel Attention Networks </strong> [<a href="https://arxiv.org/pdf/1807.02758.pdf">PDF</a>] [<a href="papers/ECCV-2018-RCAN_supp.pdf">Supp</a>] [<a href="https://github.com/yulunzhang/RCAN">PyTorch</a>] [Results]<br />
                <strong>Yulun Zhang</strong>, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, Yun Fu<br />
                <em>European Conference on Computer Vision (<strong>ECCV 2018</strong>), Munich, Germany, Sep. 2018.</em><br />
              </p>
            </div>
          </div>
        </li>
        
        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Support Neighbor Loss for Person Re-Identification </strong> [<a href="https://arxiv.org/abs/1808.06030">PDF</a>] [<a href="https://github.com/kailigo/SN_loss_for_reID">Code</a>] [Results]<br />
                Kai Li, Zhengming Ding, Kunpeng Li, <strong>Yulun Zhang</strong>, Yun Fu<br />
                <em>ACM Multimedia (<strong>ACM MM 2018</strong>), Seoul, Korea, Oct. 2018.</em><br />
              </p>
            </div>
          </div>
        </li>
        
        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Residual Dense Network for Image Super-Resolution </strong> [<a href="http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhang_Residual_Dense_Network_CVPR_2018_paper.pdf">PDF</a>] [<a href="https://github.com/yulunzhang/RDN">Torch</a>] [<a href="https://github.com/thstkdgus35/EDSR-PyTorch">PyTorch</a>] [<a href="https://pan.baidu.com/s/1jKmu14y">Results</a>]<br />
                <strong>Yulun Zhang</strong>, Yapeng Tian, Yu Kong, Bineng Zhong, Yun Fu<br />
                <em>IEEE Computer Vision and Pattern Recognition (<strong>CVPR 2018</strong>), Salt Lake City, USA, Jun. 2018. </em>(<strong>Spotlight</strong>)<br />
              </p>
            </div>
          </div>
        </li>
        <li>
          <div align="justify">
            <div align="justify">
              <p><strong>Adaptive Local Nonparametric Regression for Fast Single Image Super‐Resolution </strong> [<a href="papers/VCIP-2015-ALNR-Zhang.pdf">PDF</a>] [<a href="https://drive.google.com/drive/folders/0B7arHHh7oU7geHBMcjBfd2J3N00?usp=sharing">Code</a>] [<a href="http://pan.baidu.com/s/1ckfACQ">Code-Baidu-with mode</a>]<br />
                <strong>Yulun Zhang</strong>, Yongbing Zhang, Jian Zhang, Haoqian Wang, Xingzheng Wang, Qionghai Dai<br />
                <em>IEEE Visual Communications and Image Processing (<strong>VCIP 2015</strong>), Singapore, Dec. 2015.</em> (<strong>Oral</strong>) <span class="STYLE180"><strong><a href="img/VCIP2015best student paper-web.jpg">(Best Student Paper Award)</a></strong></span> <br />
              </p>
            </div>
          </div>
        </li>
        
            <li>
              <div align="justify">
                <div align="justify">
                  <p><strong>Image Super-Resolution based on Dictionary Learning and Anchored Neighborhood Regression with Mutual Inconherence </strong> [<a href="papers/ICIP-2015-Image Super-Resolution-Zhang.pdf">PDF</a>]<br />
                    <strong>Yulun Zhang</strong>, Kaiyu Gu, Yongbing Zhang, Jian Zhang, Qionghai Dai <br />
                    <em>IEEE International Conference on Image Processing  (<strong>ICIP 2015</strong>),  Quebec, Canada, Sep. 2015. </em>(<strong>Poster</strong>) </p>
                </div>
              </div>
            </li>
            <li>
              <div align="justify">
                <div align="justify"> 
                  <p><strong>Single Image Super-Resolution via Iterative Collaborative Representation </strong> [<a href="papers/PCM-2015-Iterative-collaborative-Zhang.pdf">PDF</a>] [<a href="https://github.com/yulunzhang/CRC-SISR">Code-Github</a>] [<a href="http://pan.baidu.com/s/1dEBPvf7">Code-Baidu</a>] <br />
                    <strong>Yulun Zhang</strong>,  Yongbing Zhang, Jian Zhang, Haoqian Wang, Qionghai Dai <br />
                    <em>Paciﬁc-Rim Conference on Multimedia  (<strong>PCM 2015</strong>), Gwangju, Korea, Sep. 2015. </em>(<strong>Oral</strong>)                </p>
                </div>
              </div>
            </li>
            <li>
              <div align="justify">
                <div align="justify"> 
                  <p><strong>Single Depth Image Super-Resolution via A Dual Sparsity Model </strong> [<a href="papers/ICME-2015-Single-depth-Zhang.pdf">PDF</a>]<br />
                    <strong>Yulun Zhang</strong>, Yongbing Zhang,  Qionghai Dai <br />
                  <em>IEEE ICME Workshop on Hot Topics in 3D (<strong>Hot3D</strong>), Torino, Italy, Jun. 2015. </em>(<strong>Oral</strong>) </p>
                </div>
              </div>
            </li>
            <li>
              <div align="justify">
                <div align="justify"> 
                  <p><strong>NTIRE 2017 Challenge on Single Image
Super-Resolution: Methods and Results </strong> [<a href="papers/Timofte-CVPRW-2017.pdf">PDF</a>]<br />
                    Radu Timofte, Eirikur Agustsson, Luc Van Gool, ..., Xintao Wang, Yapeng Tian, Ke Yu, <strong>Yulun Zhang</strong>, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao, ..., et al. <br />
                    <em>IEEE CVPR New Trends in Image Restoration
and Enhancement workshop and challenge on image super-resolution (<strong>CVPR NTIRE</strong>), Hawaii, USA, Jul. 2017. </em></p>
                </div>
              </div>
            </li>
            <li>
              <div align="justify">
                <div align="justify"> 
                  <p><strong>Decompressed Video Enhancement via Accurate Regression Prior </strong> [<a href="papers/VCIP-2016-Decompressed-Video-Shen.pdf">PDF</a>]<br />
                    Tao Shen, <strong>Yulun Zhang</strong>, Yongbing Zhang, Xingzheng Wang, Haoqian Wang,  Qionghai Dai <br />
                    <em>IEEE Visual Communications and Image Processing (<strong>VCIP 2016</strong>), Chengdu, China, Dec. 2016. </em>(<strong>Oral</strong>) </p>
                </div>
              </div>
            </li>
            <li>
              <div align="justify">
                <div align="justify"> <strong>Single Image Super-Resolution via Projective Dictionary Learning with Anchored Neighborhood Regression</strong> [<a href="papers/VCIP-2016-Single-image-Feng.pdf">PDF</a>]<br />
                  Yihui Feng, Yongbing Zhang, <strong>Yulun Zhang</strong>, Tao Shen,  Qionghai Dai <br />
                <em>IEEE Visual Communications and Image Processing (<strong>VCIP 2016</strong>), Chengdu, China, Dec. 2016. </em>(<strong>Oral</strong>)                </div>
              </div>
            </li>
            <!--<li>
              <div align="justify">
                <div align="justify"> 
                  <p><strong>NTIRE 2017 Challenge on Single Image
Super-Resolution: Methods and Results </strong> [PDF]<br />
                    Radu Timofte, ..., <strong>Yulun Zhang</strong>, ..., et al.  <br />
                    <em>IEEE CVPR New Trends in Image Restoration
and Enhancement workshop and challenge on image super-resolution (<strong>CVPR NITRE</strong>), Hawaii, USA, Jul. 2017. </em> </p>
                </div>
              </div>
            </li>-->
        </ol></td>
      </tr>
    </tbody>
  </table>
  <hr />
  <p class="STYLE85"><span style="font-size: 22pt"><span class="STYLE157" style="font-family: 'Monotype Corsiva'"><a name="Activities" id="Activities"></a><span class="STYLE258">Professional Activities</span></span></span></p>
<span class="STYLE248" style="font-family: 'Monotype Corsiva'">-PC Member</span></blockquote>
<blockquote>
  <ul type="square">
    <li class="STYLE200"> AAAI'2019</li>
    <!--<li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE Transactions on Neural Networks and Learning Systems</a></li>-->
  </ul>
<span class="STYLE248" style="font-family: 'Monotype Corsiva'">-Reviewers</span></blockquote>
<blockquote>
  <ul type="square">
    <li class="STYLE200"><a href="http://cvpr2019.thecvf.com/">CVPR'2019</a></li>
    <li class="STYLE200"><a href="http://iccv2019.thecvf.com/">ICCV'2019</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine Intelligence</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits System and Video Technology</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5962385">IEEE Transactions on Neural Networks and Learning Systems</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia</a></li>
    <li class="STYLE200"><a href="http://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6745852">IEEE Transactions on Computational Imaging</a></li>
    <li class="STYLE200"><a href="https://ees.elsevier.com/cviu/">Computer Vision and Image Understanding</a></li>
  </ul>
<!--
<span class="STYLE178" style="font-family: 'Monotype Corsiva'">-</span><span class="STYLE248" style="font-family: 'Monotype Corsiva'">Attend Conferences (Oral or Poster) and Invited Talks </span> </blockquote>
<blockquote>
  <ul type="square">
    <li class="STYLE200"><strong>Invited Talk:</strong> Adaptive Local Nonparametric Regression for Fast Single Image Super‐Resolution, Singapore, Dec. 2015 </li>
    <li class="STYLE200"><strong>Invited Talk:</strong> Single Image Super-Resolution via Iterative Collaborative Representation, Gwangju, Korea, Sep. 2015 </li>
    <li class="STYLE200"><strong>Invited Talk:</strong> Single Depth Image Super-Resolution via A Dual Sparsity Model, Torino, Italy, Jun. 2015 </li>
    <li class="STYLE200">Image Super-Resolution based on Dictionary Learning and Anchored Neighborhood Regression with Mutual Inconherence, ICIP2015, Quebec, Canada, Sep. 2015 </li>
  </ul>
<span class="STYLE248" style="font-family: 'Monotype Corsiva'">-Memberships</span></blockquote>
<blockquote>
  <ul type="square">
    <li class="STYLE200">Student Member, IEEE</li>
    <li class="STYLE200">Student Member, CCF
      <span style="font-size: 22pt"><span class="STYLE257" style="font-size: 18pt"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
      <o:p></o:p>
      </span></span></span><br />
    </li>
  </ul>
-->
  <p class="STYLE85"><span style="font-size: 22pt"><span class="STYLE251" style="font-family: 'Monotype Corsiva'"><span class="STYLE157" style="font-family: 'Monotype Corsiva'"><a name="Awards" id="Awards"></a></span><span class="STYLE262">Awards</span></span><span class="STYLE262" style="font-size: 18pt"><b 
style="mso-bidi-font-weight: normal"><span 
style="FONT-FAMILY: 'Bauhaus 93'; mso-bidi-font-family: Arial">
    <o:p></o:p>
  </span></b></span></span></p>
  <ul>
  	<li class="STYLE200">ICLR Travel Award,  2019</li>
    <li class="STYLE200">PhD Network Travel Grant, Northeastern University, USA, 2018</li>
    <li class="STYLE200">Dean's Fellowship, Northeastern University, USA, 2017</li>
    <li class="STYLE200"><a href="http://suisf.sz.edu.cn/20170713gg.htm">Shenzhen Universiade International Scholarship</a>, 2017</li>
    <li class="STYLE200">Excellent Graduate of Beijing,  Beijing, 2017</li>
    <li class="STYLE200">Excellent Graduate in Department of Automation,  Tsinghua University, 2017</li>
    <li class="STYLE200">Excellent Master Thesis Award, Tsinghua University, 2017</li>
    <li class="STYLE200">National Scholarship (Ministry of Education, China, Top 2%), 2016</li>
    <li class="STYLE200"><a href="img/VCIP2015best student paper-web.jpg">Best Student Paper Award</a> at IEEE Visual Communications and Image Processing (VCIP), 2015</li>
    <li class="STYLE200">Jingzhi Research Award in Tsinghua University, 2015</li>
  </ul>
  <hr />
  <p class="STYLE85"><span style="font-size: 22pt"><span class="STYLE157" style="font-family: 'Monotype Corsiva'"><a name="Links" id="Links"></a><span class="STYLE258">Useful Links</span></span></span> </p>
  <ul class="STYLE223">
    <!--<li class="STYLE189"><a href="https://csjianzhang.github.io/link/">Reproducible Research Websites </a></li>
    <li class="STYLE189"><a href="https://csjianzhang.github.io/link/">Academic Journals</a></li>
    <li class="STYLE189"><a href="https://csjianzhang.github.io/link/">Scholars' Homepage </a></li>-->
    <li class="STYLE189">Collaborators: <a href="http://media.au.tsinghua.edu.cn/qhdai.html" target="_blank" rel="nofollow">Qionghai Dai</a> (THU),  <a href="http://medialab.sz.tsinghua.edu.cn/people/YongbingZhang.html" target="_blank" rel="nofollow">Yongbing Zhang</a> (THU), <a href="https://jianzhang.tech/" target="_blank" rel="nofollow">Jian Zhang</a> (PKU), <a href="http://yapengtian.org/" target="_blank" rel="nofollow">Yapeng Tian</a> (U of R), <span class="STYLE189"><a href="https://sites.google.com/site/kunpengli1994/" target="_blank" rel="nofollow">KunpengLi</a> (NEU), <a href="http://kailigo.github.io/" target="_blank" rel="nofollow">Kai Li</a> (NEU)<br />
    </span></li>
    <li class="STYLE189"><a href="http://www.cvpapers.com/">CVPapers </a></li>
    <li class="STYLE189">Journal impact: <a href="papers/journal_impact/2018JournalImpactFactor.pdf">2018</a></li>
    <li class="STYLE189"><a href="https://scholar.google.com/citations?view_op=top_venues&amp;hl=en&amp;vq=eng_computervisionpatternrecognition">Top publications on Computer Vision & Pattern Recognition</a></li>
    <li class="STYLE189"><a href="https://github.com/YapengTian/Single-Image-Super-Resolution">Resources for Image Super-Resolution</a></li>
    <li class="STYLE189"><a href="https://github.com/yulunzhang/video-enhancement">Resources for Video Enhancement</a></li>
    <!--<li class="STYLE189"><a href="https://docs.google.com/document/d/1AfVob92KORBRfSCepRG47j6BqESQWJCSVJzeVSjpNiU/edit?usp=sharing">Doc </a></li>
    <li class="STYLE189"><a href="https://drive.google.com/file/d/1edHZKsccSjAsHPsRas3jQMePGUvXNquk/view?usp=sharing">PPT </a></li>
    <li class="STYLE189"><a href="style_transfer_results/style_transfer_visual_comparisons.html">Style transfer results </a></li>-->
  </ul>
</blockquote>
<p><span class="STYLE189 STYLE263">Created on 2017/06/22. Last update : 2019/04/08</span></p>
<p>    
<!-- Start of StatCounter Code for Default Guide -->
<script type="text/javascript">
var sc_project=11376711; 
var sc_invisible=0; 
var sc_security="f65f77d8"; 
var scJsHost = (("https:" == document.location.protocol) ?
"https://secure." : "http://www.");
document.write("<sc"+"ript type='text/javascript' src='" +
scJsHost+
"statcounter.com/counter/counter.js'></"+"script>");
</script>
<noscript>
</noscript>
<noscript><div class="statcounter"><a title="web analytics"
href="http://statcounter.com/" target="_blank"><img
class="statcounter"
src="//c.statcounter.com/11376711/0/f65f77d8/0/" alt="web
analytics"></a></div></noscript>
<!-- End of StatCounter Code for Default Guide -->
<a href="https://clustrmaps.com/site/19ncr"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=jIdUd0dDYkE8CiqptfhnfiWcZHCc5p62dIsontyW-FQ&cl=ffffff" /></a>
</body>
</html>
