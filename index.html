<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Yulun Zhang</title>
    <meta name="author" content="Yulun  Zhang">
    <meta name="description" content="&lt;p&gt; Associate Professor&lt;br&gt; Office: 5-517 Software Building, AI Institute, Shanghai Jiao Tong University&lt;br&gt; Email: yulun100@gmail.com&lt;/p&gt;
">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700%7CRoboto+Slab:100,300,400,500,700%7CMaterial+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9C%8C%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://localhost:4000/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav sticky-bottom-footer">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item active">
                <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a>
              </li>
              
              <!--  -->
              <!-- Blog -->
              <!-- <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li> -->
              
              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">Publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/service/">Service</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/others/">Others</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      <!-- <!DOCTYPE html> -->
<!-- <html> -->
<!-- <head> -->
    <!-- https://github.com/tholman/cursor-effects -->
    <!-- <script type="module"> -->
        <!-- import { fairyDustCursor } from "https://unpkg.com/cursor-effects@latest/dist/esm.js"; -->
        <!-- new fairyDustCursor(); -->
    <!-- </script> -->
<!-- </head> -->

<!-- https://github.com/tholman/cursor-effects -->
<!-- <script type="module">
    import { fairyDustCursor } from "https://unpkg.com/cursor-effects@latest/dist/esm.js";
    new fairyDustCursor();
</script> -->

<div class="post">


  <article>
    <div class="row">
        <div class="col-sm-3">
            
            <!-- <img style="width: 170px;border-radius: 10px" src="/assets/img/prof_pic.jpg"> -->
            <img style="height: 175px;border-radius: 10px" src="/assets/img/prof_pic.jpg">
            
            
        </div>
    
        <div class="col-sm-9">
            <h1 class="post-title">
            Yulun Zhang
            </h1>
            <p class="desc"></p>
<p> Associate Professor<br> Office: 5-517 Software Building, AI Institute, Shanghai Jiao Tong University<br> Email: yulun100@gmail.com</p>

            <div class="social">
                <div class="contact-icons">
                <a href="https://orcid.org/0000-0002-2288-5079" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a>
            <a href="https://scholar.google.com/citations?user=ORmLjWoAAAAJ&amp;hl" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a>
            <a href="https://www.semanticscholar.org/author/2410227" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a>
            <a href="https://github.com/yulunzhang" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a>
            <a href="https://www.linkedin.com/in/yulun-zhang-1116b5b9" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a>
            <a href="http://dblp.org/pers/hd/z/Zhang:Yulun" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a>
            

                </div>
            </div>
   
        </div>
    </div>

    <div class="clearfix">
      <p>I am a tenure-track associate professor at Shanghai Jiao Tong University. Previously, I was a postdoctoral researcher at Computer Vision Lab, ETH Zürich, Switzerland. I obtained my Ph.D. degree from Department of Electrical &amp; Computer Engineering, Northeastern University, USA, in Aug. 2021. Before that I received my master degree from the Department of Automation, Tsinghua University, China, in Jul. 2017 and B.E degree from School of Electronic Engineering, Xidian University, China, in Jul. 2013. 
<!-- <font color="white"><a href="./files/CV_Yulun.pdf" rel="external nofollow noopener" target="_blank">(CV)</a></font> --></p>

<p>My research interest broadly includes machine learning and computer vision. Specifically, I focus on image/video restoration (e.g., super-resolution, denoising, deblurring), synthesis (e.g., style transfer, texture transfer), biomedical image enhancement and analysis, deep model compression (e.g., network pruning, quantization), computational imaging (e.g., spectral compressive imaging), etc. I am/was an Area Chair for CVPR’(2023-2024), ICCV’2023, ECCV’2024, NeurIPS’2023, ICLR’2024, ICML’2024, ACM MM’2024, IJCAI’2024, PRCV’2024 and Senior Program Committee (SPC) member for IJCAI’(2021-2023), AAAI’(2023-2024).</p>

<!--<strong>For prospective collaborators</strong>: We have multiple positions for Postdoc/Ph.D./Master/Intern researchers. If you are interested in joining/visitng Computer Vision Lab or remotely working with us, please email me with your resume.-->

<!-- <div class="alert alert-info">
<b><font color="blue">Openings: We are looking for self-motivated undergraduate interns, graduate (Master/Ph.D.) students, and postdocs to join our group at SJTU. If you are interested, please email me with your resume.</font></b>
</div> -->

<div class="alert alert-info">
<b><font color="DeepPink"><a href="https://cvlai.net/ntire/2024/" rel="external nofollow noopener" target="_blank">Call for papers and participation<br>
NTIRE 2024</a> challenges@CVPR 2024:  <a href="https://codalab.lisn.upsaclay.fr/competitions/17553" rel="external nofollow noopener" target="_blank">Image Super-Resolution (x4)</a>, <a href="https://codalab.lisn.upsaclay.fr/competitions/17640" rel="external nofollow noopener" target="_blank">Low Light Enhancement</a>, et al.</font></b>
</div>
<!-- <div class="alert alert-info">
<b><font color="blue">I will be joining Shanghai Jiao Tong University (SJTU) as a tenure-track associate professor in 2024 Spring.<br>
Openings: We are looking for self-motivated undergraduate interns and graduate students, and postdocs to join our group at SJTU. Please read the <a href="./files/openings.pdf" rel="external nofollow noopener" target="_blank">note (申请须知)</a> bebore email me.</font></b>
</div> -->

    </div>


    
                
          <div class="news">
            <h2>News</h2>
            <div class="table-responsive" style="max-height: 20vw">
              <table class="table table-sm table-borderless">
               
                <tr>
                  <!-- <th scope="row">Feb 29, 2024</th> -->
                  <th scope="row">Feb 2024</th>
                  <td>
                    5 papers accepted to <strong>CVPR 2024</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jan 31, 2024</th> -->
                  <th scope="row">Jan 2024</th>
                  <td>
                    I am serving as an Area Chair for <strong>ECCV 2024</strong>, <strong>ICML 2024</strong>, and <strong>PRCV 2024</strong>. 3 papers accepted to <strong>ICLR 2024</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 12, 2023</th> -->
                  <th scope="row">Dec 2023</th>
                  <td>
                    We release <a href="https://dposer.github.io" rel="external nofollow noopener" target="_blank">DPoser</a>, a robust 3D human pose prior leveraging diffusion models (<a href="https://dposer.github.io" rel="external nofollow noopener" target="_blank">project</a>, <a href="https://github.com/moonbow721/DPoser" rel="external nofollow noopener" target="_blank">code</a>, <a href="https://arxiv.org/abs/2312.05541" rel="external nofollow noopener" target="_blank">paper</a>).
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Nov 23, 2023</th> -->
                  <th scope="row">Nov 2023</th>
                  <td>
                    I am serving as an Area Chair for <strong>ACM MM 2024</strong> and  <strong>IJCAI 2024 </strong>. We have also released several works: <a href="https://github.com/zhengchen1999/PromptSR" rel="external nofollow noopener" target="_blank">PromptSR</a> (text prompt in image super-resolution), <a href="https://github.com/ZHITENGLI/BiDRN" rel="external nofollow noopener" target="_blank">BiDRN</a> (binarization in 3D whole-body human mesh recovery), <a href="https://github.com/caojiezhang/DeqIR" rel="external nofollow noopener" target="_blank">DeqIR</a> (parallel sampling in diffusion-based image restoration), and <a href="https://github.com/ChunmingHe/Reti-Diff" rel="external nofollow noopener" target="_blank">Reti-Diff</a> (Retinex-based latent DM and Transformer for illumination degradation image restoration).
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Sep 29, 2023</th> -->
                  <th scope="row">Sep 2023</th>
                  <td>
                    4 papers accepted to <strong>NeurIPS 2023</strong>. Among them, <a href="https://github.com/zhengchen1999/HI-Diff" rel="external nofollow noopener" target="_blank">HI-Diff</a> is a diffusion model for realistic image deblurring. <a href="https://github.com/caiyuanhao1998/BiSCI" rel="external nofollow noopener" target="_blank">BiSCI</a> is the first work about binarization in spectral compressive imaging.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Aug 16, 2023</th> -->
                  <th scope="row">Aug 2023</th>
                  <td>
                    I am serving as an Area Chair for <strong>ICLR 2024</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 14, 2023</th> -->
                  <th scope="row">Jul 2023</th>
                  <td>
                    9 papers accepted to <strong>ICCV 2023</strong> and 2 papers accepted to <strong>ACM MM 2023</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jun 24, 2023</th> -->
                  <th scope="row">Jun 2023</th>
                  <td>
                    I am serving as an Area Chair for <strong>CVPR 2024</strong> and a Senior Program Committee (SPC) member for <strong>AAAI 2024</strong>. 1 paper about <a href="https://github.com/Zj-BinXia/MRDA" rel="external nofollow noopener" target="_blank">blind SR</a> is accepted to <strong>TIP</strong>. 1 paper is accepted to MICCAI 2023. <a href="https://github.com/SHI-Labs/Pyramid-Attention-Networks" rel="external nofollow noopener" target="_blank">Pyramid Attention Networks for Image Restoration</a> is accepted to IJCV.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">May 2, 2023</th> -->
                  <th scope="row">May 2023</th>
                  <td>
                    I am serving as an Associate Editor for <strong>Multimedia Tools and Applications (MTAP)</strong>. 1 paper accepted to <strong>TIP</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Apr 30, 2023</th> -->
                  <th scope="row">Apr 2023</th>
                  <td>
                    1 paper accepted to <strong>TPAMI</strong> and 1 paper accepted to <strong>ICML 2023</strong>. I am serving as a Reviewer for <strong>ACM MM 2023</strong>. We are also collecting papers about <a href="https://github.com/yulunzhang/awesome-diffusion-low-level-vision" rel="external nofollow noopener" target="_blank">Diffusion Models in Low-Level Vision</a>. Welcome to make your contributions!
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Mar 7, 2023</th> -->
                  <th scope="row">Mar 2023</th>
                  <td>
                    I am serving as an Area Chair for <strong>NeurIPS 2023</strong> and a Reviewer for <strong>MICCAI 2023</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Feb 27, 2023</th> -->
                  <th scope="row">Feb 2023</th>
                  <td>
                    6 papers accepted to <strong>CVPR 2023</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jan 21, 2023</th> -->
                  <th scope="row">Jan 2023</th>
                  <td>
                    3 papers accepted to <strong>ICLR 2023</strong>, 1 paper accepted to <strong>ISBI 2023</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 9, 2022</th> -->
                  <th scope="row">Dec 2022</th>
                  <td>
                    I am serving as a Senior Program Committee (SPC) member for <strong>IJCAI 2023</strong> and Reviewer for <strong>ICML 2023</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Nov 21, 2022</th> -->
                  <th scope="row">Nov 2022</th>
                  <td>
                    I am serving as an Area Chair for <strong>ICCV 2023</strong>. We have 2 papers accepted to <strong>AAAI 2023</strong>. They are about lightweight SR (<a href="https://github.com/Sun1992/HPUN" rel="external nofollow noopener" target="_blank">HPUN</a>) and hyperspectral image denoising (<a href="https://github.com/MyuLi/SST" rel="external nofollow noopener" target="_blank">SST</a>).
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Oct 4, 2022</th> -->
                  <th scope="row">Oct 2022</th>
                  <td>
                    I am serving as an Area Chair for <strong>CVPR 2023</strong>. We have 1 paper accepted to <strong>TIP</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Sep 15, 2022</th> -->
                  <th scope="row">Sep 2022</th>
                  <td>
                    We have 2 papers accepted to <strong>NeurIPS 2022</strong>. They are about image restoration (<a href="https://github.com/zhengchen1999/CAT" rel="external nofollow noopener" target="_blank">CAT</a>) and  spectral compressive imaging (<a href="https://github.com/caiyuanhao1998/MST" rel="external nofollow noopener" target="_blank">DAUHST</a>).
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 15, 2022</th> -->
                  <th scope="row">Jul 2022</th>
                  <td>
                    I am serving as a Senior Program Committee (SPC) member for <strong>AAAI 2023</strong> and reviewer for <strong>ICLR 2023</strong>. We have 5 papers accepted to <strong>ECCV 2022</strong> and 1 paper accepted to <strong>TPAMI</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jun 15, 2022</th> -->
                  <th scope="row">Jun 2022</th>
                  <td>
                    We have released the codebase for <a href="https://github.com/caiyuanhao1998/MST" rel="external nofollow noopener" target="_blank">Spectral Compressive Imaging</a>. We have 1 paper accepted to <strong>TPAMI</strong> and 2 papers accepted to <strong>ACM MM 2022</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">May 15, 2022</th> -->
                  <th scope="row">May 2022</th>
                  <td>
                    We have 2 papers accepted to <strong>ICML 2022</strong>. Our paper <a href="https://github.com/yulunzhang/RCAN" rel="external nofollow noopener" target="_blank">RCAN</a> ranks top 10 most influential papers based on citations in ECCV 2018. See <a href="https://www.paperdigest.org/2022/05/most-influential-eccv-papers-2022-05/" rel="external nofollow noopener" target="_blank">Most Influential ECCV Papers</a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Apr 21, 2022</th> -->
                  <th scope="row">Apr 2022</th>
                  <td>
                    We have 2 papers accepted to <strong>IJCAI 2022</strong>. We won the first place in <a href="https://codalab.lisn.upsaclay.fr/competitions/721" rel="external nofollow noopener" target="_blank">NTIRE Spectral Reconstruction Challenge</a> at CVPR, 2022. The <a href="https://arxiv.org/abs/2204.07908" rel="external nofollow noopener" target="_blank">paper</a> and <a href="https://github.com/caiyuanhao1998/MST-plus-plus" rel="external nofollow noopener" target="_blank">codebase</a> of our solution MST++ have been released.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Mar 30, 2022</th> -->
                  <th scope="row">Mar 2022</th>
                  <td>
                    We have 3 papers (two about spectral compressive imaging, one about interpretable image SR) accepted to <strong>CVPR 2022</strong>. I am serving as reviewer for <strong>ECCV 2022</strong> and <strong>NeurIPS 2022</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jan 12, 2022</th> -->
                  <th scope="row">Jan 2022</th>
                  <td>
                    We have 1 paper accepted to <strong>TPAMI</strong> and another one accepted to <strong>ICLR 2022</strong>. I am serving as reviewer for <strong>ACM MM 2022</strong> and <strong>MICCAI 2022</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 21, 2021</th> -->
                  <th scope="row">Dec 2021</th>
                  <td>
                    I am serving as SPC for <strong>IJCAI 2022</strong> and reviewer for <strong>ICML 2022</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Sep 21, 2021</th> -->
                  <th scope="row">Sep 2021</th>
                  <td>
                    3 papers are accepted to <strong>NeurIPS 2021</strong>. I am serving as reviewer for <strong><a href="https://cvpr2022.thecvf.com/" rel="external nofollow noopener" target="_blank">CVPR 2022</a></strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 21, 2021</th> -->
                  <th scope="row">Jul 2021</th>
                  <td>
                    3 papers are accepted to <strong>ICCV 2021</strong>. I accept the invitation to the novel Program Committee Board of IJCAI with service time from 2022 to 2024.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jun 21, 2021</th> -->
                  <th scope="row">Jun 2021</th>
                  <td>
                    1 paper is accepted to <strong>TCYB</strong> and <strong>TIP</strong>. I am serving as reviewer for <a href="https://iclr.cc/" rel="external nofollow noopener" target="_blank"><strong>ICLR 2022</strong></a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Apr 21, 2021</th> -->
                  <th scope="row">Apr 2021</th>
                  <td>
                    Our real-world image denoising paper is accepted to <strong>IJCAI 2021</strong>. I am serving as reviewer  for <strong><a href="https://nips.cc/Conferences/2021/" rel="external nofollow noopener" target="_blank">NeurIPS 2021</a></strong> and <strong><a href="https://2021.acmmm.org/" rel="external nofollow noopener" target="_blank">ACM MM 2021</a></strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Mar 21, 2021</th> -->
                  <th scope="row">Mar 2021</th>
                  <td>
                    Our papers about MR image enhancement and real-world image denoising are accepted to <strong>CVPR 2021</strong>. One paper about MR image super-resolution is accepted to <strong>TCSVT</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Feb 21, 2021</th> -->
                  <th scope="row">Feb 2021</th>
                  <td>
                    Our paper <a href="https://github.com/yulunzhang/RDN" rel="external nofollow noopener" target="_blank">RDN</a> ranks top 10 most influential papers based on citations in CVPR 2018. See <a href="https://www.paperdigest.org/2021/02/most-influential-cvpr-papers/" rel="external nofollow noopener" target="_blank">Most Influential CVPR Papers</a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jan 21, 2021</th> -->
                  <th scope="row">Jan 2021</th>
                  <td>
                    Our <a href="https://arxiv.org/abs/2012.09243" rel="external nofollow noopener" target="_blank">Neural Pruning</a> paper (<a href="https://github.com/MingSun-Tse/Regularization-Pruning" rel="external nofollow noopener" target="_blank">code</a>) is accepted to <strong>ICLR 2021</strong>. I am serving as reviewer  for <strong><a href="http://iccv2021.thecvf.com/home" rel="external nofollow noopener" target="_blank">ICCV 2021</a></strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 21, 2020</th> -->
                  <th scope="row">Dec 2020</th>
                  <td>
                    I am serving as a Senior Program Committee (SPC) member for <strong><a href="https://ijcai-21.org/" rel="external nofollow noopener" target="_blank">IJCAI 2021</a></strong> and PC member for <strong><a href="https://icml.cc/Conferences/2021" rel="external nofollow noopener" target="_blank">ICML 2021</a></strong>, <strong><a href="https://miccai2021.org/en/" rel="external nofollow noopener" target="_blank">MICCAI 2021</a></strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Sep 21, 2020</th> -->
                  <th scope="row">Sep 2020</th>
                  <td>
                    We have 1 paper accepted to <strong>TNNLS</strong> and another one accepted to <strong>NeurIPS 2020</strong>. Code will be available soon.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 21, 2020</th> -->
                  <th scope="row">Jul 2020</th>
                  <td>
                    We have 2 papers accepted to <strong>ECCV 2020</strong>. Code/data will be available soon.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jun 21, 2020</th> -->
                  <th scope="row">Jun 2020</th>
                  <td>
                    We release the <a href="https://github.com/SHI-Labs/Pyramid-Attention-Networks" rel="external nofollow noopener" target="_blank">code</a> for our paper: <a href="https://arxiv.org/pdf/2004.13824.pdf" rel="external nofollow noopener" target="_blank">Pyramid Attention Networks for Image Restoration</a>
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Feb 21, 2020</th> -->
                  <th scope="row">Feb 2020</th>
                  <td>
                    We have 3 papers accepted to <strong>CVPR 2020</strong>. Congratulations to all authors!
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jan 21, 2020</th> -->
                  <th scope="row">Jan 2020</th>
                  <td>
                    We have 1 paper accepted to <strong>TPAMI</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 21, 2019</th> -->
                  <th scope="row">Dec 2019</th>
                  <td>
                    We release the TensforFlow code and pre-trained models for ICCV19MST at <a href="https://github.com/yulunzhang/MST" rel="external nofollow noopener" target="_blank">MST</a>. The PyTorch code for MST is on the way.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Apr 21, 2019</th> -->
                  <th scope="row">Apr 2019</th>
                  <td>
                    We release all the train/test codes and pre-trained models for ICLR19RNAN at <a href="https://github.com/yulunzhang/RNAN" rel="external nofollow noopener" target="_blank">RNAN</a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Dec 25, 2018</th> -->
                  <th scope="row">Dec 2018</th>
                  <td>
                    We have 1 paper accepted to <strong>ICLR 2019</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 21, 2018</th> -->
                  <th scope="row">Jul 2018</th>
                  <td>
                    We have 1 paper accepted to <strong>ACM MM 2018</strong> and 1 paper accepted to <strong>ECCV 2018</strong>. PyTorch version for our CVPR18RDN has been implemented by Nguyễn Trần Toàn (trantoan060689@gmail.com) and merged into <a href="https://github.com/thstkdgus35/EDSR-PyTorch" rel="external nofollow noopener" target="_blank">EDSR-PyTorch</a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jun 21, 2018</th> -->
                  <th scope="row">Jun 2018</th>
                  <td>
                    I accept the invitation to serve as Program Committee member of <strong>AAAI 2019</strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Feb 21, 2018</th> -->
                  <th scope="row">Feb 2018</th>
                  <td>
                    I will intern to <strong><a href="https://research.adobe.com/" rel="external nofollow noopener" target="_blank">Adobe Research</a></strong> (San Jose, CA) this summer. We have 1 paper accepted to <strong>CVPR 2018</strong> as spotlight. All the codes are available at <a href="https://github.com/yulunzhang/RDN" rel="external nofollow noopener" target="_blank">Github</a>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">Jul 21, 2017</th> -->
                  <th scope="row">Jul 2017</th>
                  <td>
                    I recieve ‘<strong>Excellent Graduate of Beijing</strong>’ award, ‘<strong>Excellent Graduate in Department of Automation, Tsinghua University</strong>’ award, <strong>Excellent Master Thesis Award, Tsinghua University</strong>’ award, and <strong><a href="http://suisf.sz.edu.cn/20170713gg.htm" rel="external nofollow noopener" target="_blank">Shenzhen Universiade International Scholarship</a></strong>.
 
                  </td>
                </tr> 
                <tr>
                  <!-- <th scope="row">May 21, 2017</th> -->
                  <th scope="row">May 2017</th>
                  <td>
                    We have 1 IEEE  <strong>TSMC</strong> paper accepted. <a href="http://yulunzhang.com/img/CVPR17NTIRE-SecondAward.jpg" rel="external nofollow noopener" target="_blank">Our team (HelloSR: Xintao Wang, Yapeng Tian, Ke Yu, Yulun Zhang, Shixiang Wu, Chao Dong, Liang Lin, Yu Qiao) ranks <strong>2nd</strong> place</a> in <a href="http://www.vision.ee.ethz.ch/ntire17/" rel="external nofollow noopener" target="_blank">NTIRE Image Super-Resolution Challenge</a>.
 
                  </td>
                </tr> 
              </table>
            </div> 
          </div>

    

    
      
          <div class="publications">
            <h2>Recent Publications</h2>
            <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="zamfir2024see" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">See More Details: Efficient Image Super-Resolution by Experts Mining</div>
          <!-- Author -->
          <div class="author">
          

          Eduard Zamfir, Zongwei Wu*, Nancy Mehta, <em>Yulun Zhang*</em>, and Radu Timofte</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2402.03412</em> 2024
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2402.03412</em>
          
          
            (<b>arXiv</b>),
          
          
          2024
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2402.03412.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/eduardzamfir/seemoredetails" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="lu2023dposer" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">DPoser: Diffusion Model as Robust 3D Human Pose Prior</div>
          <!-- Author -->
          <div class="author">
          

          Junzhe Lu, Jing Lin, Hongkun Dou, <em>Yulun Zhang*</em>, Yue Deng, and Haoqian Wang*</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2312.05541</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2312.05541</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2312.05541.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/moonbow721/DPoser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
            <a href="https://dposer.github.io" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="chen2023image" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Image Super-Resolution with Text Prompt Diffusion</div>
          <!-- Author -->
          <div class="author">
          

          Zheng Chen, <em>Yulun Zhang</em>, Jinjin Gu, Xin Yuan, Linghe Kong, Guihai Chen, and Xiaokang Yang</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2303.06373</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2303.06373</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.06373.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/zhengchen1999/PromptSR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="li2023binarized" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Binarized 3D Whole-body Human Mesh Recovery</div>
          <!-- Author -->
          <div class="author">
          

          Zhingteng Li, <em>Yulun Zhang</em>, Jing Lin, Haotong Qin, Jinjin Gu, Xin Yuan, Linghe Kong, and Xiaokang Yang</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2311.14323</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2311.14323</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2311.14323.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/ZHITENGLI/BiDRN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="he2023reti" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model</div>
          <!-- Author -->
          <div class="author">
          

          Chunming He, Chengyu Fang, <em>Yulun Zhang</em>, Kai Li, Longxiang Tang, Chenyu You, Fengyang Xiao, Zhenhua Guo, and Xiu Li</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2311.11638</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2311.11638</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2311.11638.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/ChunmingHe/Reti-Diff" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023cooperative" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Cooperative Hardware-Prompt Learning for Snapshot Compressive Imaging</div>
          <!-- Author -->
          <div class="author">
          

          Jiamian Wang, Zongliang Wu, <em>Yulun Zhang</em>, Xin Yuan, Tao Lin, and Zhiqiang Tao</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2306.01176</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2306.01176</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2306.01176.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge" style="background-color:#00ab37"><a href="https://arxiv.org/list/cs.CV/recent" rel="external nofollow noopener" target="_blank">arXiv</a></abbr></div>

        <!-- Entry bib key -->
        <div id="xia2023diffi2i" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">DiffI2I: Efficient Diffusion Model for Image-to-Image Translation</div>
          <!-- Author -->
          <div class="author">
          

          Bin Xia, <em>Yulun Zhang</em>, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, Radu Timofte, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>arXiv preprint arXiv:2308.13767</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>arXiv preprint arXiv:2308.13767</em>
          
          
            (<b>arXiv</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2308.13767.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Zj-BinXia/DiffIR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition" rel="external nofollow noopener" target="_blank">CVPR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="cao2023deep" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Deep Equilibrium Diffusion Restoration with Parallel Sampling</div>
          <!-- Author -->
          <div class="author">
          

          Jiezhang Cao, Yue Shi, Kai Zhang, <em>Yulun Zhang</em>, Radu Timofte, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Computer Vision and Pattern Recognition</em> 2024
          </div> -->
          <div class="periodical">
          
            <em>In Computer Vision and Pattern Recognition</em>
          
          
            (<b>CVPR</b>),
          
          
          2024
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2311.11600.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/caojiezhang/DeqIR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" rel="external nofollow noopener" target="_blank">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="chen2023recursive" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Recursive Generalization Transformer for Image Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Zheng Chen, <em>Yulun Zhang*</em>, Jinjin Gu, Linghe Kong*, and Xiaokang Yang</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2024
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Learning Representations</em>
          
          
            (<b>ICLR</b>),
          
          
          2024
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.06373.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/zhengchen1999/RGT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" rel="external nofollow noopener" target="_blank">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="zhang2023xformer" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Xformer: Hybrid X-Shaped Transformer for Image Denoising</div>
          <!-- Author -->
          <div class="author">
          

          Jiale Zhang, <em>Yulun Zhang*</em>, Jinjin Gu, Jiahua Dong, Linghe Kong*, and Xiaokang Yang</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2024
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Learning Representations</em>
          
          
            (<b>ICLR</b>),
          
          
          2024
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.06373.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/gladzhang/Xformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems" rel="external nofollow noopener" target="_blank">NeurIPS Spotlight</a></abbr></div>

        <!-- Entry bib key -->
        <div id="qin2023quantsr" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">QuantSR: Accurate Low-bit Quantization for Efficient Image Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Haotong Qin<sup>†</sup>, Yulun Zhang<sup>†,*</sup>, Yifu Ding, Yifan Liu, Xianglong Liu<sup>*</sup>, Martin Danelljan, and Fisher Yu</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In Advances in Neural Information Processing Systems</em>
          
          
            (<b>NeurIPS Spotlight</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://openreview.net/pdf?id=3gamyee9Yh" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/htqin/QuantSR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems" rel="external nofollow noopener" target="_blank">NeurIPS Spotlight</a></abbr></div>

        <!-- Entry bib key -->
        <div id="chen2023hierarchical" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Hierarchical Integration Diffusion Model for Realistic Image Deblurring</div>
          <!-- Author -->
          <div class="author">
          

          Zheng Chen, <em>Yulun Zhang*</em>, Ding Liu, Bin Xia, Jinjin Gu, Linghe Kong*, and Xin Yuan</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In Advances in Neural Information Processing Systems</em>
          
          
            (<b>NeurIPS Spotlight</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2305.12966.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/zhengchen1999/HI-Diff" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Neural_Information_Processing_Systems" rel="external nofollow noopener" target="_blank">NeurIPS</a></abbr></div>

        <!-- Entry bib key -->
        <div id="cai2023binarized" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Binarized Spectral Compressive Imaging</div>
          <!-- Author -->
          <div class="author">
          

          Yuanhao Cai, Yuxin Zheng, Jing Lin, Xin Yuan, <em>Yulun Zhang*</em>, and Haoqian Wang*</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In Advances in Neural Information Processing Systems</em>
          
          
            (<b>NeurIPS</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2305.10299" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/caiyuanhao1998/BiSCI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div>

        <!-- Entry bib key -->
        <div id="chen2023dual" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Dual Aggregation Transformer for Image Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Zheng Chen, <em>Yulun Zhang*</em>, Jinjin Gu, Linghe Kong*, Xiaokang Yang, and Fisher Yu</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Computer Vision</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Computer Vision</em>
          
          
            (<b>ICCV</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2308.03364.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/zhengchen1999/DAT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023iterative" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Iterative Soft Shrinkage Learning for Efficient Image Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Jiamian Wang, Huan Wang, <em>Yulun Zhang*</em>, Yun Fu, and Zhiqiang Tao*</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Computer Vision</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Computer Vision</em>
          
          
            (<b>ICCV</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.09650.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Jiamian-Wang/Iterative-Soft-Shrinkage-SR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div>

        <!-- Entry bib key -->
        <div id="xia2023diffir" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">DiffIR: Efficient Diffusion Model for Image Restoration</div>
          <!-- Author -->
          <div class="author">
          

          Bin Xia, <em>Yulun Zhang</em>, Shiyin Wang, Yitong Wang, Xinglong Wu, Yapeng Tian, Wenming Yang, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Computer Vision</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Computer Vision</em>
          
          
            (<b>ICCV</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.09472.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Zj-BinXia/DiffIR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div>

        <!-- Entry bib key -->
        <div id="cai2023retinexformer" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Retinexformer: One-stage Retinex-based Transformer for Low-light Image Enhancement</div>
          <!-- Author -->
          <div class="author">
          

          Yuanhao Cai, Hao Bian, Jing Lin, Haoqian Wang*, Radu Timofte, and <em>Yulun Zhang*</em>
</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Computer Vision</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Computer Vision</em>
          
          
            (<b>ICCV</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2303.06705.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/caiyuanhao1998/Retinexformer" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Computer_Vision" rel="external nofollow noopener" target="_blank">ICCV</a></abbr></div>

        <!-- Entry bib key -->
        <div id="tel2023alignment" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Alignment-free HDR Deghosting with Semantics Consistent Transformer</div>
          <!-- Author -->
          <div class="author">
          

          Steven Tel, Zongwei Wu, <em>Yulun Zhang*</em>, Barthelemy Heyrman, Cedric Demonceaux, Radu Timofte, and Dominique Ginhac</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Computer Vision</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Computer Vision</em>
          
          
            (<b>ICCV</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2305.18135.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Zongwei97/SCTNet" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition" rel="external nofollow noopener" target="_blank">CVPR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="cao2023ciaosr" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">CiaoSR: Continuous Implicit Attention-in-Attention Network for Arbitrary-Scale Image Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Jiezhang Cao, Qin Wang, Yongqin Xian, Yawei Li, Bingbing Ni, Zhiming Pi, Kai Zhang*, <em>Yulun Zhang*</em>, Radu Timofte, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Computer Vision and Pattern Recognition</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In Computer Vision and Pattern Recognition</em>
          
          
            (<b>CVPR</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2212.04362.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/caojiezhang/CiaoSR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/Conference_on_Computer_Vision_and_Pattern_Recognition" rel="external nofollow noopener" target="_blank">CVPR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="wang2023lgbpn" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">LG-BPN: Local and Global Blind-Patch Network for Self-Supervised Real-World Denoising</div>
          <!-- Author -->
          <div class="author">
          

          Zichun Wang, Ying Fu, Ji Liu, and <em>Yulun Zhang</em>
</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In Computer Vision and Pattern Recognition</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In Computer Vision and Pattern Recognition</em>
          
          
            (<b>CVPR</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/pdf/2304.00534.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Wang-XIaoDingdd/LGBPN" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" rel="external nofollow noopener" target="_blank">ICLR Spotlight</a></abbr></div>

        <!-- Entry bib key -->
        <div id="xia2023basic" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Accurate Image Restoration with Attention Retractable Transformer</div>
          <!-- Author -->
          <div class="author">
          

          Jiale Zhang, <em>Yulun Zhang*</em>, Jinjin Gu, Yongbing Zhang, Linghe Kong*, and Xin Yuan</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Learning Representations</em>
          
          
            (<b>ICLR Spotlight</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2210.01427" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/gladzhang/ART" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" rel="external nofollow noopener" target="_blank">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="xia2023basid" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Basic Binary Convolution Unit for Binarized Image Restoration Network</div>
          <!-- Author -->
          <div class="author">
          

          Bin Xia, <em>Yulun Zhang</em>, Yitong Wang, Yapeng Tian, Wenming Yang, Radu Timofte, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Learning Representations</em>
          
          
            (<b>ICLR</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2210.00405" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Zj-BinXia/BBCU" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge"><a href="https://en.wikipedia.org/wiki/International_Conference_on_Learning_Representations" rel="external nofollow noopener" target="_blank">ICLR</a></abbr></div>

        <!-- Entry bib key -->
        <div id="xia2023knowledge" class="col-sm-10">
        
          <!-- Title -->
          <div class="title">Knowledge Distillation based Degradation Estimation for Blind Super-Resolution</div>
          <!-- Author -->
          <div class="author">
          

          Bin Xia, <em>Yulun Zhang</em>, Yitong Wang, Yapeng Tian, Wenming Yang, Radu Timofte, and Luc Van Gool</div>

          <!-- Journal/Book title and date -->
          
          <!-- <div class="periodical">
            <em>In International Conference on Learning Representations</em> 2023
          </div> -->
          <div class="periodical">
          
            <em>In International Conference on Learning Representations</em>
          
          
            (<b>ICLR</b>),
          
          
          2023
          
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="https://arxiv.org/abs/2211.16928" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a>
            <a href="https://github.com/Zj-BinXia/KDSR" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a>
          </div>

          
        </div>
      </div>
</li>
</ol>
          </div>

    

    
    <a href="https://clustrmaps.com/site/19ncr" title="Visit tracker" rel="external nofollow noopener" target="_blank"><img src="//www.clustrmaps.com/map_v2.png?d=jIdUd0dDYkE8CiqptfhnfiWcZHCc5p62dIsontyW-FQ&amp;cl=ffffff" style="width: 0px;"></a>
  </article>

</div>

<!-- </html> -->
    </div>

    <!-- Footer -->    <footer class="sticky-bottom mt-5">
      <div class="container">
        © Copyright 2024 Yulun  Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
